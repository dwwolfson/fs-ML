
library(tidyverse)
library(lubridate)

############################
# Bring together all the exiftool metadata output
setwd('C:/Users/apdwwolfson/Documents/Projects/Photo_Database/Machine_Learning/CEAH_Exif_output')
root_path<-'C:/Users/apdwwolfson/Documents/Projects/Photo_Database/Machine_Learning/CEAH_Exif_output'
ca_path<-paste(root_path, "CA_exiftool_output", sep='/')
fl_path<-paste(root_path, "FL_output", sep='/')

####################
# TAG Images (in one level above CA and FL image folders)
tag<-read_csv('All_Tag_output.csv')
names(tag)
cols_keep<-c('Directory','FileName', 'DateTimeOriginal' )
tag<-tag[,cols_keep]

##################
#CA Images
setwd(ca_path)
ca_files<-list.files()

ca_db<-data.frame()

#combine in a loop (doesn't take too long)
for(i in 1:length(ca_files)){
  temp<-read_csv(ca_files[i])
  temp<-temp[,cols_keep]
  ca_db<-rbind(ca_db, temp)
  print(i)
}

###############################
#fl Images
setwd(fl_path)
fl_files<-list.files()

fl_db<-data.frame()

#combine in a loop 
for(i in 1:length(fl_files)){
  temp<-read_csv(fl_files[i])
  temp<-temp[,cols_keep]
  fl_db<-rbind(fl_db, temp)
  print(i)
}
##########################
# Combine all
tag$study<-'tejon_TAG'
ca_db$study<-'tejon'
fl_db$study<-'florida'
df<-rbind(tag, ca_db, fl_db)

# remove records where the DateTime didn't get recorded
apply(is.na(df), 2, sum)
df<-df[!is.na(df$DateTimeOriginal),]

############################################################################
# Now merge this with the model output
preds<-read_csv('C:/Users/apdwwolfson/Documents/Projects/Photo_Database/Machine_Learning/output_from_all_unclassified/L1_preds.csv' )

# Now some name wrangling to be able to merge these two datasets together.
# It's probably easiest to merge on just the filename, since they should all be unique
# I want the Camera ID in the name as well becasuse I'm pretty sure each camera has it's 
# own unique ID number(concatenated with cam ID)

# I'll separate on the "/", at least for the preds dataframe
preds$FileName<-sapply(preds$IMG_PATH, function(x)
  strsplit(x, "/")[[1]][4])

# Now merge
alldat<-left_join(preds, df)   
alldat<-alldat[!is.na(alldat$DateTimeOriginal),]
##################################
# Add date and time specific columns

# can trim a few columns
alldat<-alldat[, c("FileName", "Directory", "study", "DateTimeOriginal", 
                   "GUESS1","GUESS2", "GUESS3","GUESS4","GUESS5","CONFIDENCE1","CONFIDENCE2",
                   "CONFIDENCE3", "CONFIDENCE4","CONFIDENCE5")]
summary(nchar(alldat$DateTimeOriginal)) #all 19 characters, that's good

alldat$study<-as.factor(alldat$study)

#convert to posix.ct
unique(alldat$study)
fl<-alldat[alldat$study=='florida',]
ca<-alldat[alldat$study=='tejon'|alldat$study=='tejon_TAG',]
ca$DateTimeOriginal<-ymd_hms(ca$DateTimeOriginal, tz = "US/Pacific") # 40 failed to parse
fl$DateTimeOriginal<-ymd_hms(fl$DateTimeOriginal, tz = "US/Eastern") # 160 filed to parse
alldat<-rbind(ca, fl)
alldat$year<-year(alldat$DateTimeOriginal)
alldat$week<-week(alldat$DateTimeOriginal)
alldat$day<-day(alldat$DateTimeOriginal)
alldat$hour<-hour(alldat$DateTimeOriginal)
alldat<-alldat[!is.na(alldat$day),] #filter on one of the new columns to remove rows where the dates didn't parse


#write out dataset in it's current state
setwd('C:/Users/apdwwolfson/Documents/Projects/Photo_Database/Machine_Learning/trained model output/Data/all_CEAH')
write.csv(alldat, "all_results_with_dates.csv")